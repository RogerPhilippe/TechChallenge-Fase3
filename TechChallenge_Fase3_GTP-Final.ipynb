{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RTNxpMRj-C2"
      },
      "source": [
        "* TECH CHALLENGE - FASE 03: FINE-TUNING AMAZON PRODUCTS\n",
        "* Versão Simplificada com OpenAI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-y2GIi5kYJ0"
      },
      "source": [
        "* 1: INSTALAÇÃO E CONFIGURAÇÃO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jQ6saeoAeTIP"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai pandas gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "19L5OGc_epG_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbYeD446evcx"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3JwVJtBe7n6",
        "outputId": "e4e700c8-daf1-4941-fdda-53c131db156b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conexão com OpenAI estabelecida!\n",
            "Modelos disponíveis para fine-tuning: ['gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914']\n"
          ]
        }
      ],
      "source": [
        "# Testar conexão\n",
        "try:\n",
        "    models = client.models.list()\n",
        "    print(\"Conexão com OpenAI estabelecida!\")\n",
        "    print(\"Modelos disponíveis para fine-tuning:\", [m.id for m in models.data if 'gpt-3.5-turbo' in m.id][:3])\n",
        "except Exception as e:\n",
        "    print(f\"Erro na conexão: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq6-U8QCkm1S"
      },
      "source": [
        "* 2: UPLOAD E ANÁLISE DO DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv3cr5QDkshJ"
      },
      "outputs": [],
      "source": [
        "!gunzip trn.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFg9WGq9pmFo",
        "outputId": "4e6fe030-7dc6-4bfc-fc51-bb43f4bf0961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset encontrado!\n"
          ]
        }
      ],
      "source": [
        "# Verificar se arquivo existe ou criar exemplo\n",
        "try:\n",
        "    with open('/content/trn.json', 'r') as f:\n",
        "        test_read = f.read(1)\n",
        "    print(\"Dataset encontrado!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nArquivo não existe!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZV896M7pwRQ"
      },
      "outputs": [],
      "source": [
        "# Analisar dataset\n",
        "def analyze_dataset():\n",
        "    print(\"\\nANÁLISE DO DATASET:\")\n",
        "\n",
        "    data = []\n",
        "    with open('/content/trn.json', 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 10:  # Analisar primeiros 10\n",
        "                break\n",
        "            try:\n",
        "                item = json.loads(line)\n",
        "                data.append(item)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if data:\n",
        "        print(f\"{len(data)} exemplos carregados\")\n",
        "        print(f\"Campos: {list(data[0].keys())}\")\n",
        "\n",
        "        # Mostrar exemplo\n",
        "        print(f\"\\nExemplo:\")\n",
        "        print(f\"Título: {data[0]['title']}\")\n",
        "        print(f\"Descrição: {data[0]['content'][:100]}...\")\n",
        "\n",
        "        return data\n",
        "    else:\n",
        "        print(\"Erro ao carregar dados\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fkpr_LCp64i",
        "outputId": "2494678d-8574-44ad-f243-12c94be50a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ANÁLISE DO DATASET:\n",
            "10 exemplos carregados\n",
            "Campos: ['uid', 'title', 'content', 'target_ind', 'target_rel']\n",
            "\n",
            "Exemplo:\n",
            "Título: Girls Ballet Tutu Neon Pink\n",
            "Descrição: High quality 3 layer ballet tutu. 12 inches in length...\n"
          ]
        }
      ],
      "source": [
        "sample_data = analyze_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4d8vWWBqD6J"
      },
      "source": [
        "* 3: PREPARAÇÃO DOS DADOS PARA FINE-TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l0yMvpHqE2A"
      },
      "outputs": [],
      "source": [
        "def prepare_openai_dataset(max_examples=50):\n",
        "    \"\"\"Prepara dados no formato da OpenAI para fine-tuning\"\"\"\n",
        "\n",
        "    print(f\"Preparando {max_examples} exemplos para fine-tuning...\")\n",
        "\n",
        "    training_data = []\n",
        "\n",
        "    with open('/content/trn.json', 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= max_examples:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                item = json.loads(line)\n",
        "                title = item.get('title', '').strip()\n",
        "                content = item.get('content', '').strip()\n",
        "\n",
        "                if not title or not content:\n",
        "                    continue\n",
        "\n",
        "                # Criar exemplos de treinamento\n",
        "                questions = [\n",
        "                    f\"Me fale sobre: {title}\",\n",
        "                    f\"Quais as características de: {title}\",\n",
        "                    f\"Descreva este produto: {title}\"\n",
        "                ]\n",
        "\n",
        "                for question in questions[:2]:  # 2 exemplos por produto\n",
        "                    training_example = {\n",
        "                        \"messages\": [\n",
        "                            {\n",
        "                                \"role\": \"system\",\n",
        "                                \"content\": \"Você é um assistente especializado em produtos da Amazon. Forneça informações detalhadas sobre produtos baseado nas descrições fornecidas.\"\n",
        "                            },\n",
        "                            {\n",
        "                                \"role\": \"user\",\n",
        "                                \"content\": question\n",
        "                            },\n",
        "                            {\n",
        "                                \"role\": \"assistant\",\n",
        "                                \"content\": content\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                    training_data.append(training_example)\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "    print(f\"{len(training_data)} exemplos preparados\")\n",
        "\n",
        "    # Salvar em formato JSONL para OpenAI\n",
        "    with open('/content/training_data.jsonl', 'w', encoding='utf-8') as f:\n",
        "        for example in training_data:\n",
        "            f.write(json.dumps(example, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    print(\"Dados salvos em '/content/training_data.jsonl'\")\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBcT8sPsqcwE",
        "outputId": "70745429-25eb-458d-a142-44386cb7fe8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparando 25 exemplos para fine-tuning...\n",
            "22 exemplos preparados\n",
            "Dados salvos em '/content/training_data.jsonl'\n",
            "\n",
            "Exemplo de dados preparados:\n",
            "{\n",
            "  \"messages\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"Você é um assistente especializado em produtos da Amazon. Forneça informações detalhadas sobre produtos baseado nas descrições fornecidas.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"Me fale sobre: Girls Ballet Tutu Neon Pink\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"assistant\",\n",
            "      \"content\": \"High quality 3 layer ballet tutu. 12 inches in length\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Preparar dados\n",
        "training_examples = prepare_openai_dataset(25)  # 25 produtos = ~50 exemplos\n",
        "\n",
        "# Mostrar exemplo\n",
        "print(\"\\nExemplo de dados preparados:\")\n",
        "print(json.dumps(training_examples[0], indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtpqY6OsqmSh"
      },
      "source": [
        "* 4: TESTE DO MODELO BASE (ANTES DO FINE-TUNING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGa7Y1Unqm3n"
      },
      "outputs": [],
      "source": [
        "def test_base_model():\n",
        "    \"\"\"Testa GPT-3.5 sem fine-tuning\"\"\"\n",
        "\n",
        "    print(\"TESTE DO MODELO BASE (SEM FINE-TUNING)\")\n",
        "\n",
        "    test_questions = [\n",
        "        \"Me fale sobre fones de ouvido Sony WH-1000XM4\",\n",
        "        \"Quais as características do Samsung Galaxy S21 Ultra\",\n",
        "        \"Descreva o MacBook Air com M1\"\n",
        "    ]\n",
        "\n",
        "    for question in test_questions:\n",
        "        print(f\"\\nPergunta: {question}\")\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Você é um assistente de produtos.\"},\n",
        "                    {\"role\": \"user\", \"content\": question}\n",
        "                ],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            answer = response.choices[0].message.content\n",
        "            print(f\"Resposta BASE: {answer}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhK0fnJnr58k",
        "outputId": "ea15fc52-e275-4ad4-88c2-4dba00059376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTE DO MODELO BASE (SEM FINE-TUNING)\n",
            "\n",
            "Pergunta: Me fale sobre fones de ouvido Sony WH-1000XM4\n",
            "Resposta BASE: Os fones de ouvido Sony WH-1000XM4 são conhecidos por sua excelente qualidade de som e cancelamento de ruído líder de mercado. Eles oferecem uma experiência de áudio imersiva, com drivers de 40mm que proporcionam graves profundos e agudos cristalinos. \n",
            "\n",
            "Além disso, esses fones possuem tecnologia de cancelamento de ruído adaptável, que ajusta automaticamente a intensidade do cancelamento de acordo com o ambiente ao seu redor. Isso garante uma experiência auditiva tranquila, seja em um ambiente movimentado ou em um local mais silencioso.\n",
            "\n",
            "Os Sony WH-1000XM4 também contam\n",
            "\n",
            "Pergunta: Quais as características do Samsung Galaxy S21 Ultra\n",
            "Resposta BASE: O Samsung Galaxy S21 Ultra é um smartphone topo de gama da Samsung, lançado em 2021. Algumas das características principais deste modelo incluem:\n",
            "\n",
            "- Tela: Dynamic AMOLED de 6,8 polegadas com resolução de 3200 x 1440 pixels e taxa de atualização de até 120Hz\n",
            "- Processador: Exynos 2100 ou Snapdragon 888 (dependendo da região)\n",
            "- Memória RAM: 12GB ou 16GB\n",
            "- Armazenamento interno: 128GB, 256GB ou 512GB\n",
            "- Câmeras traseiras: Sistema de câmera quádrupla com sensor principal de \n",
            "\n",
            "Pergunta: Descreva o MacBook Air com M1\n",
            "Resposta BASE: O MacBook Air com M1 é um laptop da Apple que possui um processador M1, desenvolvido pela própria empresa. Este processador oferece um desempenho poderoso, com excelente eficiência energética. O MacBook Air é conhecido por ser leve e fino, tornando-o ideal para quem precisa de mobilidade sem comprometer a performance. Além disso, ele possui uma tela Retina de alta resolução, teclado confortável, Touch ID para segurança e várias opções de armazenamento. Em resumo, o MacBook Air com M1 é uma excelente opção para quem busca um laptop potente, leve e com uma ótima duração de bateria.\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "test_base_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0V2mDYpsDTv"
      },
      "source": [
        "* 5: UPLOAD DOS DADOS E FINE-TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weLCFFlUsESG"
      },
      "outputs": [],
      "source": [
        "def upload_and_finetune():\n",
        "    \"\"\"Faz upload dos dados e executa fine-tuning na OpenAI\"\"\"\n",
        "\n",
        "    print(\"INICIANDO PROCESSO DE FINE-TUNING\")\n",
        "\n",
        "    try:\n",
        "        # 1. Upload do arquivo de treinamento\n",
        "        print(\"Fazendo upload dos dados de treinamento...\")\n",
        "\n",
        "        with open('/content/training_data.jsonl', 'rb') as f:\n",
        "            training_file = client.files.create(\n",
        "                file=f,\n",
        "                purpose='fine-tune'\n",
        "            )\n",
        "\n",
        "        print(f\"Arquivo enviado! ID: {training_file.id}\")\n",
        "\n",
        "        # 2. Criar job de fine-tuning\n",
        "        print(\"Criando job de fine-tuning...\")\n",
        "\n",
        "        fine_tune_job = client.fine_tuning.jobs.create(\n",
        "            training_file=training_file.id,\n",
        "            model=\"gpt-3.5-turbo-1106\",  # Modelo base para fine-tuning\n",
        "            hyperparameters={\n",
        "                \"n_epochs\": 3,  # Número de épocas\n",
        "                \"batch_size\": 1,\n",
        "                \"learning_rate_multiplier\": 0.1\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"Job criado! ID: {fine_tune_job.id}\")\n",
        "        print(f\"Status: {fine_tune_job.status}\")\n",
        "\n",
        "        # Salvar IDs importantes\n",
        "        job_info = {\n",
        "            \"training_file_id\": training_file.id,\n",
        "            \"job_id\": fine_tune_job.id,\n",
        "            \"status\": fine_tune_job.status\n",
        "        }\n",
        "\n",
        "        with open('/content/finetune_info.json', 'w') as f:\n",
        "            json.dump(job_info, f, indent=2)\n",
        "\n",
        "        print(\"Informações salvas em '/content/finetune_info.json'\")\n",
        "        return fine_tune_job\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro no fine-tuning: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_utJXumRsMNZ",
        "outputId": "55b01de9-f97a-4c4f-8371-5b6e63faa8a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INICIANDO PROCESSO DE FINE-TUNING\n",
            "Fazendo upload dos dados de treinamento...\n",
            "Arquivo enviado! ID: file-P8CfbxPRChTrLj4uvPUiwC\n",
            "Criando job de fine-tuning...\n",
            "Job criado! ID: ftjob-g6uQNtY3iHSWBSZhBuCdeU3a\n",
            "Status: validating_files\n",
            "Informações salvas em '/content/finetune_info.json'\n"
          ]
        }
      ],
      "source": [
        "finetune_job = upload_and_finetune()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu5hOYp7s51r"
      },
      "source": [
        "* 6: MONITORAR PROGRESSO DO FINE-TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G48ZIbjNs6kN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def monitor_finetune_progress():\n",
        "    \"\"\"Monitora o progresso do fine-tuning automaticamente com progress bar\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Carregar informações do job\n",
        "        with open('/content/finetune_info.json', 'r') as f:\n",
        "            job_info = json.load(f)\n",
        "\n",
        "        job_id = job_info['job_id']\n",
        "        print(f\"Monitorando job: {job_id}\")\n",
        "        print(\"Verificando status automaticamente...\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                # Verificar status\n",
        "                job = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "                # Limpar output anterior\n",
        "                clear_output(wait=True)\n",
        "\n",
        "                # Mostrar status atual\n",
        "                print(\"=\" * 60)\n",
        "                print(\"MONITORAMENTO AUTOMÁTICO DO FINE-TUNING\")\n",
        "                print(\"=\" * 60)\n",
        "                print(f\"Job ID: {job.id}\")\n",
        "                print(f\"Status: {job.status}\")\n",
        "                print(f\"Modelo base: {job.model}\")\n",
        "\n",
        "                # Progress bar visual\n",
        "                if job.status == \"running\":\n",
        "                    print(\"\\nProcessando... ⏳\")\n",
        "                    print(\"█████████████████████░░░░░ 75% (estimado)\")\n",
        "                elif job.status == \"validating\":\n",
        "                    print(\"\\nValidando modelo... 🔍\")\n",
        "                    print(\"████████████████████████░ 95% (estimado)\")\n",
        "                elif job.status == \"succeeded\":\n",
        "                    print(\"\\nConcluído! ✅\")\n",
        "                    print(\"█████████████████████████ 100%\")\n",
        "                elif job.status == \"failed\":\n",
        "                    print(\"\\nFalhou! ❌\")\n",
        "                    print(\"Error:\", job.error)\n",
        "                    break\n",
        "\n",
        "                # Se terminou com sucesso\n",
        "                if job.finished_at and job.status == \"succeeded\":\n",
        "                    print(f\"\\nConcluído em: {job.finished_at}\")\n",
        "                    print(f\"Modelo fine-tuned: {job.fine_tuned_model}\")\n",
        "\n",
        "                    # Salvar modelo ID\n",
        "                    job_info['fine_tuned_model'] = job.fine_tuned_model\n",
        "                    job_info['status'] = 'succeeded'\n",
        "                    with open('/content/finetune_info.json', 'w') as f:\n",
        "                        json.dump(job_info, f, indent=2)\n",
        "\n",
        "                    print(\"\\nFINE-TUNING CONCLUÍDO COM SUCESSO!\")\n",
        "                    print(\"Agora você pode executar a próxima célula.\")\n",
        "                    break\n",
        "\n",
        "                # Se falhou\n",
        "                elif job.status == 'failed':\n",
        "                    print(f\"\\nFalhou: {job.error}\")\n",
        "                    job_info['status'] = 'failed'\n",
        "                    with open('/content/finetune_info.json', 'w') as f:\n",
        "                        json.dump(job_info, f, indent=2)\n",
        "                    break\n",
        "\n",
        "                # Se ainda em progresso\n",
        "                else:\n",
        "                    current_time = datetime.now().strftime(\"%d/%m/%Y às %H:%M:%S\")\n",
        "                    print(f\"\\nStatus: {job.status}\")\n",
        "                    print(f\"Última verificação: {current_time}\")\n",
        "                    print(\"Verificando novamente em 30 segundos...\")\n",
        "                    print(\"\\n(Pressione Ctrl+C para parar o monitoramento)\")\n",
        "                    time.sleep(30)  # Esperar 30 segundos\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n\\nMonitoramento interrompido pelo usuário.\")\n",
        "                print(\"Execute esta célula novamente para continuar monitorando.\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Erro na verificação: {e}\")\n",
        "                print(\"Tentando novamente em 30 segundos...\")\n",
        "                time.sleep(30)\n",
        "\n",
        "        return job\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao iniciar monitoramento: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dGavZSWtD04",
        "outputId": "02b84637-7869-48e4-d3ff-86d4e348fd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "MONITORAMENTO AUTOMÁTICO DO FINE-TUNING\n",
            "============================================================\n",
            "Job ID: ftjob-g6uQNtY3iHSWBSZhBuCdeU3a\n",
            "Status: succeeded\n",
            "Modelo base: gpt-3.5-turbo-1106\n",
            "\n",
            "Concluído! ✅\n",
            "█████████████████████████ 100%\n",
            "\n",
            "Concluído em: 1757341408\n",
            "Modelo fine-tuned: ft:gpt-3.5-turbo-1106:personal::CDX4FhCa\n",
            "\n",
            "FINE-TUNING CONCLUÍDO COM SUCESSO!\n",
            "Agora você pode executar a próxima célula.\n"
          ]
        }
      ],
      "source": [
        "print(\"Iniciando monitoramento automático...\")\n",
        "final_job = monitor_finetune_progress()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNWzsr-QtOnb"
      },
      "source": [
        "* 7: TESTE DO MODELO FINE-TUNED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AL3RFgYhtNRL"
      },
      "outputs": [],
      "source": [
        "def test_finetuned_model():\n",
        "    \"\"\"Testa o modelo após fine-tuning\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Carregar informações do modelo\n",
        "        with open('/content/finetune_info.json', 'r') as f:\n",
        "            job_info = json.load(f)\n",
        "\n",
        "        if 'fine_tuned_model' not in job_info:\n",
        "            print(\"Modelo ainda não está pronto. Verifique o status primeiro.\")\n",
        "            return\n",
        "\n",
        "        model_id = job_info['fine_tuned_model']\n",
        "        print(f\"TESTE DO MODELO FINE-TUNED: {model_id}\")\n",
        "\n",
        "        test_questions = [\n",
        "            \"Me fale sobre fones de ouvido Sony WH-1000XM4\",\n",
        "            \"Quais as características do Samsung Galaxy S21 Ultra\",\n",
        "            \"Descreva o MacBook Air com M1\"\n",
        "        ]\n",
        "\n",
        "        for question in test_questions:\n",
        "            print(f\"\\nPergunta: {question}\")\n",
        "\n",
        "            # Teste com modelo fine-tuned\n",
        "            response_ft = client.chat.completions.create(\n",
        "                model=model_id,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Você é um assistente especializado em produtos da Amazon.\"},\n",
        "                    {\"role\": \"user\", \"content\": question}\n",
        "                ],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            answer_ft = response_ft.choices[0].message.content\n",
        "            print(f\"Resposta FINE-TUNED: {answer_ft}\")\n",
        "\n",
        "            # Comparar com modelo base\n",
        "            response_base = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Você é um assistente de produtos.\"},\n",
        "                    {\"role\": \"user\", \"content\": question}\n",
        "                ],\n",
        "                max_tokens=150,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            answer_base = response_base.choices[0].message.content\n",
        "            print(f\"Resposta BASE: {answer_base}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro no teste: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg0KRaictYpA",
        "outputId": "5e30f8a8-543d-44bf-e318-8f9bc142e290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTE DO MODELO FINE-TUNED: ft:gpt-3.5-turbo-1106:personal::CDX4FhCa\n",
            "\n",
            "Pergunta: Me fale sobre fones de ouvido Sony WH-1000XM4\n",
            "Resposta FINE-TUNED: Os fones de ouvido Sony WH-1000XM4 são conhecidos por oferecer uma excelente qualidade de som e cancelamento de ruído. Eles vêm com tecnologia de cancelamento de ruído adaptável, o que significa que eles podem ajustar automaticamente o nível de cancelamento de ruído com base no ambiente em que você está. Além disso, eles possuem uma longa duração da bateria, permitindo até 30 horas de reprodução com uma única carga. Os WH-1000XM4 também oferecem conectividade Bluetooth e suporte para assistentes de voz, como a Alexa da Amazon. Com um design confortável e controles intuitivos,\n",
            "Resposta BASE: Os fones de ouvido Sony WH-1000XM4 são considerados uma das melhores opções de fones com cancelamento de ruído ativo disponíveis no mercado. Eles oferecem uma excelente qualidade de som, conforto e tecnologia avançada.\n",
            "\n",
            "Além do cancelamento de ruído, os WH-1000XM4 possuem uma bateria de longa duração, suporte para Bluetooth e NFC, e controles intuitivos de toque. Também possuem microfones para chamadas telefônicas com qualidade de áudio cristalina.\n",
            "\n",
            "Outro destaque é o sistema de inteligência artificial que ajusta automaticamente o cancelamento de ruído de\n",
            "--------------------------------------------------\n",
            "\n",
            "Pergunta: Quais as características do Samsung Galaxy S21 Ultra\n",
            "Resposta FINE-TUNED: O Samsung Galaxy S21 Ultra é um smartphone de alto desempenho que oferece uma série de características avançadas. Aqui estão algumas das principais características do Galaxy S21 Ultra:\n",
            "\n",
            "1. Tela: O Galaxy S21 Ultra possui uma tela Dynamic AMOLED de 6,8 polegadas com resolução de 3200 x 1440 pixels, oferecendo uma experiência visual impressionante e cores vibrantes.\n",
            "\n",
            "2. Câmeras: O dispositivo possui um sistema de câmera quad, com uma câmera principal de 108 MP, uma lente ultra-wide de 12 MP, duas lentes telefoto de 10 MP cada, e uma câmera frontal\n",
            "Resposta BASE: O Samsung Galaxy S21 Ultra é um smartphone topo de gama da Samsung, lançado em janeiro de 2021. Algumas das principais características do Galaxy S21 Ultra incluem:\n",
            "\n",
            "- Tela: Super AMOLED de 6,8 polegadas com resolução de 3200 x 1440 pixels e taxa de atualização de até 120Hz\n",
            "- Processador: Exynos 2100 (em algumas regiões) ou Qualcomm Snapdragon 888 (em outras regiões)\n",
            "- Memória RAM: 12GB ou 16GB\n",
            "- Armazenamento interno: 128GB, 256GB ou 512GB\n",
            "- Câmeras traseiras: Sistema\n",
            "--------------------------------------------------\n",
            "\n",
            "Pergunta: Descreva o MacBook Air com M1\n",
            "Resposta FINE-TUNED: O MacBook Air com M1 é um laptop fino, leve e poderoso que incorpora o processador M1, desenvolvido pela Apple. O processador M1 é um chip de 8 núcleos que oferece um desempenho excepcional em termos de velocidade e eficiência energética. Isso significa que o MacBook Air com M1 oferece um desempenho rápido e responsivo, ao mesmo tempo em que possui uma excelente vida útil da bateria.\n",
            "\n",
            "Além disso, o MacBook Air com M1 possui uma tela Retina de alta resolução, que oferece imagens nítidas e cores vibrantes. O design elegante e compacto do MacBook\n",
            "Resposta BASE: O MacBook Air com M1 é um laptop da Apple que foi lançado em 2020. Ele é alimentado pelo chip M1, desenvolvido pela própria Apple, o que proporciona um desempenho rápido e eficiente. O MacBook Air com M1 possui uma tela Retina de alta resolução, design fino e leve, teclado confortável, e uma bateria de longa duração. Além disso, ele oferece um sistema operacional macOS otimizado para o chip M1, que proporciona uma experiência de uso fluida e eficiente. É uma ótima opção para quem busca um laptop potente e portátil para tarefas do dia a\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Executar teste (só funciona depois do fine-tuning completar)\n",
        "test_finetuned_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gguJUHb32xTb"
      },
      "source": [
        "* 8: INTERFACE INTERATIVA COM GRADIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tJv3kj6u2wLh"
      },
      "outputs": [],
      "source": [
        "def create_chatbot_interface():\n",
        "    \"\"\"Cria interface Gradio para o chatbot\"\"\"\n",
        "\n",
        "    # Carregar modelo fine-tuned\n",
        "    try:\n",
        "        with open('/content/finetune_info.json', 'r') as f:\n",
        "            job_info = json.load(f)\n",
        "\n",
        "        if 'fine_tuned_model' in job_info:\n",
        "            custom_model_id = job_info['fine_tuned_model']\n",
        "            print(f\"Modelo personalizado disponível: {custom_model_id}\")\n",
        "        else:\n",
        "            custom_model_id = None\n",
        "            print(\"Modelo personalizado não encontrado\")\n",
        "\n",
        "    except:\n",
        "        custom_model_id = None\n",
        "        print(\"Arquivo de modelo não encontrado\")\n",
        "\n",
        "    def generate_response(message, history, use_custom_model):\n",
        "        \"\"\"Gera resposta usando OpenAI\"\"\"\n",
        "\n",
        "        # Escolher modelo baseado na seleção do usuário\n",
        "        if use_custom_model and custom_model_id:\n",
        "            model_id = custom_model_id\n",
        "            system_message = \"Você é um assistente especializado em produtos da Amazon. Forneça informações detalhadas e úteis sobre produtos baseado no seu treinamento específico.\"\n",
        "        else:\n",
        "            model_id = \"gpt-3.5-turbo\"\n",
        "            system_message = \"Você é um assistente de produtos. Forneça informações gerais sobre produtos.\"\n",
        "\n",
        "        # Construir contexto da conversa\n",
        "        messages = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "        # Adicionar histórico\n",
        "        for user_msg, assistant_msg in history:\n",
        "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "\n",
        "        # Adicionar mensagem atual\n",
        "        messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model_id,\n",
        "                messages=messages,\n",
        "                max_tokens=200,\n",
        "                temperature=0.7\n",
        "            )\n",
        "\n",
        "            # Adicionar indicador do modelo usado na resposta\n",
        "            model_indicator = \" [PERSONALIZADO]\" if use_custom_model and custom_model_id else \" [PADRÃO]\"\n",
        "            answer = response.choices[0].message.content + model_indicator\n",
        "\n",
        "            return answer\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Erro: {str(e)}\"\n",
        "\n",
        "    # Criar interface Gradio\n",
        "    with gr.Blocks(title=\"Amazon Product Assistant\") as demo:\n",
        "        gr.HTML(\"<h1>Assistente de Produtos Amazon - Comparação de Modelos</h1>\")\n",
        "\n",
        "        # Seletor de modelo\n",
        "        with gr.Row():\n",
        "            model_selector = gr.Radio(\n",
        "                choices=[\n",
        "                    (\"Modelo Personalizado (Fine-tuned)\", True),\n",
        "                    (\"Modelo Padrão (GPT-3.5)\", False)\n",
        "                ],\n",
        "                value=True if custom_model_id else False,\n",
        "                label=\"Escolha o Modelo\",\n",
        "                interactive=True if custom_model_id else False\n",
        "            )\n",
        "\n",
        "        # Informações dos modelos\n",
        "        if custom_model_id:\n",
        "            gr.HTML(f\"<p><strong>Modelo Personalizado:</strong> <code>{custom_model_id}</code></p>\")\n",
        "        else:\n",
        "            gr.HTML(\"<p><strong>Aviso:</strong> Modelo personalizado não disponível. Usando apenas modelo padrão.</p>\")\n",
        "\n",
        "        gr.HTML(\"<p><strong>Modelo Padrão:</strong> <code>gpt-3.5-turbo</code></p>\")\n",
        "\n",
        "        chatbot = gr.Chatbot()\n",
        "\n",
        "        with gr.Row():\n",
        "            msg = gr.Textbox(\n",
        "                placeholder=\"Faça uma pergunta sobre produtos...\",\n",
        "                label=\"Sua pergunta\",\n",
        "                scale=4\n",
        "            )\n",
        "            submit = gr.Button(\"Enviar\", scale=1)\n",
        "\n",
        "        clear = gr.Button(\"Limpar Chat\")\n",
        "\n",
        "        # Exemplos\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                \"Me fale sobre fones de ouvido Sony\",\n",
        "                \"Quais as características de smartphones Samsung?\",\n",
        "                \"Descreva produtos Apple\",\n",
        "                \"Preciso de informações sobre tênis Nike\",\n",
        "                \"O que você sabe sobre panelas elétricas?\"\n",
        "            ],\n",
        "            inputs=msg\n",
        "        )\n",
        "\n",
        "        # Informações sobre a comparação\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"background-color: #f0f0f0; padding: 10px; margin-top: 20px; border-radius: 5px;\">\n",
        "        <h3>Como comparar os modelos:</h3>\n",
        "        <ul>\n",
        "        <li><strong>Modelo Personalizado:</strong> Treinado com produtos específicos da Amazon, deve dar respostas mais detalhadas e específicas</li>\n",
        "        <li><strong>Modelo Padrão:</strong> Conhecimento geral, respostas mais genéricas sobre produtos</li>\n",
        "        <li><strong>Indicador:</strong> Cada resposta mostra [PERSONALIZADO] ou [PADRÃO] para identificar qual modelo foi usado</li>\n",
        "        </ul>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        def respond(message, chat_history, use_custom):\n",
        "            bot_message = generate_response(message, chat_history, use_custom)\n",
        "            chat_history.append((message, bot_message))\n",
        "            return \"\", chat_history\n",
        "\n",
        "        def clear_chat():\n",
        "            return []\n",
        "\n",
        "        msg.submit(respond, [msg, chatbot, model_selector], [msg, chatbot])\n",
        "        submit.click(respond, [msg, chatbot, model_selector], [msg, chatbot])\n",
        "        clear.click(clear_chat, outputs=[chatbot])\n",
        "\n",
        "    return demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "mimbff8n247v",
        "outputId": "15ee12d9-fcef-4d27-8c20-6f08294f5fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo personalizado disponível: ft:gpt-3.5-turbo-1106:personal::CDX4FhCa\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3389249057.py:83: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://36f47bb63c91fed5df.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://36f47bb63c91fed5df.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://36f47bb63c91fed5df.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Criar e executar interface\n",
        "demo = create_chatbot_interface()\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
